{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460cd9b-7867-43df-85a0-b0c7ee8eb466",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import detective.core as detective\n",
    "import detective.functions as functions\n",
    "import pandas as pd\n",
    "\n",
    "db = detective.db_from_hass_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b45b5a-fe1f-4c14-b73a-9bd2fe5c7054",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98d27af-3801-4a1c-bce1-f20681f6aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "export_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea618db9-4fe4-4f30-8892-747c9a4f8ccd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            SELECT states.state, states.last_updated_ts, states_meta.entity_id\n",
      "            FROM states\n",
      "            JOIN states_meta\n",
      "            ON states.metadata_id = states_meta.metadata_id\n",
      "            WHERE\n",
      "                states_meta.entity_id  LIKE '%sensor%'\n",
      "            AND\n",
      "                states.state NOT IN ('unknown', 'unavailable')\n",
      "            ORDER BY last_updated_ts DESC\n",
      "        LIMIT 1000000000\n",
      "The returned Pandas dataframe has 2796940 rows of data.\n"
     ]
    }
   ],
   "source": [
    "hadf = db.fetch_all_sensor_data(limit=1_000_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba1ffd6-b58b-4559-b51d-033f5e48d3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2796940 entries, 0 to 2796939\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   state            object \n",
      " 1   last_updated_ts  float64\n",
      " 2   entity_id        object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 64.0+ MB\n"
     ]
    }
   ],
   "source": [
    "hadf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7ec75-01fb-45a5-911e-5e48d4aae589",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b2349f-0052-4cad-bd50-be96afd4b20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload_2024-11-15_22-58-12.parquet\n"
     ]
    }
   ],
   "source": [
    "staging_path = \"/tmp/\"\n",
    "filename = f'upload_{export_time}.csv'\n",
    "filename_parquet = filename.split(\".\")[0] + \".parquet\"\n",
    "print(filename_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c629948a-ff67-415e-b5fb-8e841d53b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadf.to_parquet(staging_path + filename_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4862d97-fe53-4138-8186-dea4de75129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 27636\n",
      "drwxrwxrwt 1 root root     4096 Nov 15 22:59 .\n",
      "drwxr-xr-x 1 root root     4096 Nov 15 22:48 ..\n",
      "drwxr-xr-x 2 root root     4096 Nov 15 22:48 .bashio\n",
      "-rw-r--r-- 1 root root 28285435 Nov 15 22:59 upload_2024-11-15_22-58-12.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls -la /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa87ed-e81f-4da3-9bb4-1316f0231f86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility commands to create schema and table:\n",
    "cursor.execute(f\"CREATE SCHEMA `{CATALOG}`.{SCHEMA}\")\n",
    "cursor.execute(f\"CREATE TABLE `{CATALOG}`.{SCHEMA}.sensor_data (state FLOAT, last_updated_ts TIMESTAMP, entity_id STRING);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148d628-847b-49e1-8e39-4972485cb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks import sql\n",
    "\n",
    "\n",
    "with sql.connect(server_hostname            = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                 http_path                  = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                 access_token               = os.getenv(\"DATABRICKS_TOKEN\"),\n",
    "                 staging_allowed_local_path = \"/tmp/\") as connection:\n",
    "\n",
    "  with connection.cursor() as cursor:\n",
    "\n",
    "    # Write a local file to the specified path in a volume.\n",
    "    # Specify OVERWRITE to overwrite any existing file in that path.\n",
    "    cursor.execute(\n",
    "      f\"PUT '/tmp/{filename_parquet}' INTO '{DBX_VOLUMES_PATH}/{filename_parquet}' OVERWRITE\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aad254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative SQL snippet for initial load:\n",
    "f\"\"\"\n",
    "COPY INTO `{CATALOG}`.{SCHEMA}.sensor_data\n",
    "  FROM (\n",
    "    SELECT \n",
    "      TRY_CAST(state AS FLOAT) AS state, \n",
    "      TRY_CAST(last_updated_ts AS TIMESTAMP) AS last_updated_ts, \n",
    "      entity_id \n",
    "    FROM '{DBX_VOLUMES_PATH}/{filename_parquet}'\n",
    "  )\n",
    "  FILEFORMAT = parquet\n",
    "  COPY_OPTIONS ('mergeSchema' = 'true');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb80098-4e60-4147-a0a5-eb4b9b24f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sql.connect(server_hostname            = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                 http_path                  = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                 access_token               = os.getenv(\"DATABRICKS_TOKEN\"),\n",
    "                 staging_allowed_local_path = \"/tmp/\") as connection:\n",
    "\n",
    "  with connection.cursor() as cursor:\n",
    "\n",
    "    # Upsert data from the uploaded file into the table.\n",
    "    cursor.execute(\n",
    "      f\"\"\"\n",
    "      MERGE INTO `{CATALOG}`.{SCHEMA}.sensor_data AS target\n",
    "        USING (\n",
    "          SELECT \n",
    "            TRY_CAST(state AS FLOAT) AS state, \n",
    "            TRY_CAST(last_updated_ts AS TIMESTAMP) AS last_updated_ts, \n",
    "            entity_id\n",
    "          FROM read_files('{DBX_VOLUMES_PATH}/{filename_parquet}')\n",
    "        ) AS source\n",
    "        ON target.entity_id = source.entity_id AND target.last_updated_ts = source.last_updated_ts\n",
    "        WHEN MATCHED THEN\n",
    "          UPDATE SET \n",
    "            target.state = source.state,\n",
    "            target.last_updated_ts = source.last_updated_ts\n",
    "        WHEN NOT MATCHED THEN\n",
    "          INSERT (state, last_updated_ts, entity_id)\n",
    "          VALUES (source.state, source.last_updated_ts, source.entity_id);\n",
    "      \"\"\"\n",
    "    )\n",
    "\n",
    "    print(cursor.fetchall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hass-databricks-JrE4U7kN-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
